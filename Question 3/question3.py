# -*- coding: utf-8 -*-
"""question3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wC-T3GRmaZO5K1E2lol5mSc2Fah6geog
"""

# Connect colab with drive to get dataset
from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf # version=2.3.0 tensorflow is used to build the MLP
import pandas as pd # pandas is used to read/write .txt
import matplotlib.pyplot as plt #used to display
# %matplotlib inline

# Read data and divide train dataset for testing
train = pd.read_table('/content/drive/MyDrive/Question 3/train_data.txt',delim_whitespace=True)
train_data = train.iloc[0:9000,:]
test_data = train.iloc[9000:10000,:]

truth = pd.read_table('/content/drive/MyDrive/Question 3/train_truth.txt',delim_whitespace=True)
train_truth = truth.iloc[0:9000,:]
test_truth = truth.iloc[9000:10000,:]

target_test_data = pd.read_table('/content/drive/MyDrive/Question 3/test_data.txt',delim_whitespace=True)
target_test_data

"""
Initialize the MLP model and set the layers
I tried L2 regularization and dropout method to avoid overfitting,
but it seemed to be useless and increased the MSE
so I did not use them in the end
"""
model = tf.keras.Sequential(
    [
     tf.keras.layers.Dense(4,input_shape=(3,),activation='relu'),#,kernel_regularizer=tf.keras.regularizers.l2(0.001)
     
    #  tf.keras.layers.Dropout(0.01),
     tf.keras.layers.Dense(4,activation='relu'),
    #  tf.keras.layers.Dropout(0.01),
     tf.keras.layers.Dense(1)
    ]
)

# Check if the structure is right
model.summary()

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0045),
      loss='mse',
)

earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',
                            min_delta=0.0000,patience=10
)

history = model.fit(test_data,test_truth,
          epochs=500,
          callbacks=[earlystop_callback],
          validation_data=(test_data,test_truth)
          )

plt.plot(history.epoch,history.history.get('loss'),label='loss')
plt.plot(history.epoch,history.history.get('val_loss'),label='val_loss')
plt.legend()

target_test_predict = model.predict(target_test_data)

target_test_predict

np.savetxt('test_predicted.txt',(target_test_predict),header='y',comments='')